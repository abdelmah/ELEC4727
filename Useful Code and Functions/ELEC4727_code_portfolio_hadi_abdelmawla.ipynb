{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code Portfolio by Hadi Abdelmawla Containing all useful functions to help future students "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code to help with histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function in order to read a mass amount of image files and to convert them to RGB\n",
    "#in order to use this the user must define their image path \n",
    "#it returns all the images from a directory into an image dictionary that they can use later \n",
    "def read_image_files(image_path, conversion=cv2.COLOR_BGR2RGB):\n",
    "    image_files = glob.glob(os.path.join(image_path, '*')) #function in order to convert the images pass through the image path and conversion\n",
    "    image_list = [(os.path.basename(f),cv2.imread(f,conversion)) for f in image_files]\n",
    "    image_dict = {file:image for (file,image) in image_list}\n",
    "    return image_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to incriment the number of bins when it comes to histogram all the user needs to define is the number of incriments that they want and it returns the number of bins\n",
    "#this function is meant to be used in a for loop\n",
    "def bin_number(incriments):\n",
    "    number_bins = number_of_bins * incriments\n",
    "    return number_bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to create histograms from a dictionary of images with 8 bins\n",
    "#in order to use this function the user must take the image dict given from the function above and pass it into this function\n",
    "#this function returns all the histograms in a dictionary with the filename as the key\n",
    "#adjustable parameters are the number of bins and image size from [0,256]\n",
    "def generate_histogram(image_dict, number_bins=8):\n",
    "    histogram_dict = dict()\n",
    "    for filename in image_dict: # function to take the images and create histograms for each one \n",
    "        image = image_dict[filename]\n",
    "        hist0 = cv2.calcHist([image], [0], None, [number_bins], [0,256])\n",
    "        hist1 = cv2.calcHist([image], [1], None, [number_bins], [0,256])\n",
    "        hist2 = cv2.calcHist([image], [2], None, [number_bins], [0,256])\n",
    "        overall_hist = np.concatenate([hist0,hist1,hist2]).ravel()\n",
    "        hist = overall_hist / overall_hist.sum()\n",
    "        histogram_dict[filename] = hist\n",
    "    return histogram_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to compare histogram values\n",
    "#in order to use this function the user will have to generate their histograms for seperate classes in this case it was \n",
    "#class and target but the user can change that to their likeing they also have to pass in the image names\n",
    "#another thing that must be done to use this is create the OPENCV_METHODS if you don't know how to do that just google it\n",
    "#the return of this function is a dictionary containg the comparision results\n",
    "def compare_histogram(image_name, target_hist_base, class_histogram_dict):\n",
    "    results_dict = dict()\n",
    "    for (methodName, method, reverse) in OPENCV_METHODS:\n",
    "        results = {k : cv2.compareHist(target_hist_base, hist, method) for (k,hist) in sorted(class_histogram_dict.items())} #compare the histograms pass in the targets and class\n",
    "        results = sorted([(v, k) for (k, v) in results.items()], reverse = reverse)\n",
    "        results_dict[methodName] = results\n",
    "        return results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function in order to compare histogram values between the target and myster images \n",
    "#in order to use this the user will have to pass through the target image name mystery image name the target histograms and mystery histograms also know as target_hist_base_two\n",
    "#this function returns the compared mystery results in a dictionary after they have been compared\n",
    "def compare_mystery(image_name, mystery_image_name, target_hist_base, target_hist_base_two):\n",
    "    mystery_results_dict = dict()\n",
    "    for (methodName, method, reverse) in OPENCV_METHODS:\n",
    "        mystery_results = {image_name : cv2.compareHist(target_hist_base, target_hist_base_two, method)}\n",
    "\n",
    "        mystery_results_dict[methodName] = mystery_results #create a nested dictionary containing the results of the mystery images compared with the targets\n",
    "    return mystery_results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function calculates the scores of a comparision test for histograms\n",
    "#in order to use this function the user will have to pass in a tuple that contains the score and filename\n",
    "#from there the code will computate the avg median max min if the avg is less than median and a dictionary of all the average scores\n",
    "def calculate_score_range(histogram_scores_tuple): #calculate the range of scores \n",
    "    preferredTest = dict()\n",
    "    scores = [score for (score,filename) in histogram_scores_tuple] #grab the file scores from the target class compare results\n",
    "    median_score = scores[int(len(scores)/2)]\n",
    "    max_score = max(scores)\n",
    "    min_score = min(scores)\n",
    "    avg_score = sum(scores)/len(scores) #calculate the median avg max and min\n",
    "    if(avg_score < median_score): \n",
    "        pTest= [methodName]\n",
    "        preferredTest[methodName]= (avg_score)\n",
    "\n",
    "    avg_score_dict[methodName] = avg_score\n",
    "\n",
    "    return (avg_score, median_score, max_score, min_score, preferredTest, avg_score_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code to help with face detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to process images from a directory\n",
    "#have to pass the face cascade which if you don't know what it is google it\n",
    "#the directory where the files are stored \n",
    "# the function will convert the image into gray scale rgb and detect the faces in the file and return it all in one image dictionary\n",
    "def process_images_from_directory(faceCascade, directory, scaleFactor=1.1, minNeighbors=8): # process the images from the directory and create faces for them\n",
    "    imageDictionary = dict() \n",
    "    for directoryPath, directoryNames, fileNames in os.walk(directory):\n",
    "        for fileName in fileNames:\n",
    "            imageFile = os.path.join(directoryPath, fileName) \n",
    "            # Reads image into RGB for histogram comparison\n",
    "            img = cv2.imread(imageFile)\n",
    "            img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            faces = faceCascade.detectMultiScale(img_gray, scaleFactor=scaleFactor, minNeighbors=minNeighbors)\n",
    "            print(faces)\n",
    "            print(imageFile)\n",
    "            imageDictionary[fileName] = (img_gray,img_rgb, faces)  \n",
    "    return imageDictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to take an image and detect all the skin in it\n",
    "#then it goes further to mask the image in order that it only shows the skin of darker people\n",
    "#you can adjust this code by changing the filter of 205,255,255 to change the color of skin you want masked \n",
    "#the inputs are just an image \n",
    "#the output is a directory of the masked image normally then in rgb\n",
    "def skinColor_mask_hist (da_img): # this where i take the image passed and mask it for only brown skin colors\n",
    "    skin_mask_dict = dict()\n",
    "    rgb_mask_dict = dict()\n",
    "\n",
    "    imageYCrCb = cv2.cvtColor(da_img,cv2.COLOR_BGR2YCR_CB)\n",
    "    skinRegionYCrCb = cv2.inRange(imageYCrCb,min_YCrCb,max_YCrCb) # I detect the region in which there is skin\n",
    "    daimg_rgb = cv2.cvtColor(da_img, cv2.COLOR_BGR2RGB)\n",
    "    skinYCrCb = cv2.bitwise_and(daimg_rgb, daimg_rgb, mask = skinRegionYCrCb) # then mask the original image to only show skin\n",
    "    skin_mask_dict = skinYCrCb\n",
    "    lower = np.array([190, 0, 0], dtype = \"uint8\")\n",
    "    upper = np.array([205,255,255], dtype = \"uint8\") # I then define the limits of brown that I want in RGB form\n",
    "    mask = cv2.inRange(skinYCrCb, lower, upper)\n",
    "    output = cv2.bitwise_and(skinYCrCb, skinYCrCb, mask = mask) # i then mask the masked skin image to only show pixels that satisfy the limits of brown\n",
    "    rgb_mask_dict = output\n",
    "    return skin_mask_dict, rgb_mask_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#two functions to compare the amount of skin in each image \n",
    "#you have to pass in histograms and just the base image you want to compare against where it says obamatemplate0.jpg\n",
    "#Very useful in trying to limit a folder of images to only darker skin\n",
    "#returns the scores so you can compare\n",
    "def compare_histogram(image_name, target_hist_base, class_histogram_dict): # same function from pokemon\n",
    "    results_dict = dict()\n",
    "    for (methodName, method, reverse) in OPENCV_METHODS:\n",
    "        results = {k : cv2.compareHist(target_hist_base, hist, method) for (k,hist) in sorted(class_histogram_dict.items())} #compare the histograms pass in the targets and class\n",
    "        results = sorted([(v, k) for (k, v) in results.items()], reverse = reverse)\n",
    "        results_dict[methodName] = results\n",
    "        \n",
    "    return results_dict\n",
    "def compare_hist_template(masked_hist): # here is where I compare the templates against each other\n",
    "    template_scores = dict()\n",
    "    for filename in masked_hist:\n",
    "        if(filename == 'ObamaTemplate0.jpg'):\n",
    "            continue\n",
    "        template_scores[filename] = (cv2.compareHist(masked_hist_obama['ObamaTemplate0.jpg'], masked_hist[filename], cv2.HISTCMP_INTERSECT))\n",
    "    return template_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code to help with creating a cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code to define a model for a cnn\n",
    "#the user can change the amount of layers and size of each one\n",
    "#make sure you put in the correct inputshape when it asks here it is currently 28,28,1\n",
    "#also make sure to have correct number of folders you want to test where it say dense at the bottom for this there\n",
    "#were 10 folders to train thus the 10\n",
    "def define_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform',input_shape=(28, 28, 1)))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(64, kernel_size=(3, 3), activation=\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    \n",
    "    # compile model\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to create a small VGG model the user will have to pass in how many layers they want from one to five which is all of them\n",
    "# 5 layers the user needs to make sure to update the input shape and number of folders that are being trained \n",
    "#returns the test model which is ready to be trained with epochs\n",
    "def smallVgg(howmany): #created a smallvgg with the option to limit how many times it is added\n",
    "    test_model = Sequential()\n",
    "    test_model.add(Conv2D(32, (3, 3), input_shape=(28, 28, 1), padding='same', activation='relu'))\n",
    "    test_model.add(MaxPooling2D((3,3), strides=1))\n",
    "    if (howmany == 'first'):\n",
    "        test_model.add(Dense(256, activation='relu'))\n",
    "        test_model.add(Dense(10, activation='softmax'))\n",
    "        test_model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "        return test_model\n",
    "    test_model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "    test_model.add(MaxPooling2D((3,3), strides=1))\n",
    "    if howmany == 'second':\n",
    "        test_model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "        return test_model\n",
    "    test_model.add(Conv2D(64, (3,3), padding='same', activation='relu'))\n",
    "    test_model.add(MaxPooling2D((3,3), strides=1))\n",
    "    if howmany == 'third':\n",
    "        test_model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "        return test_model\n",
    "    test_model.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
    "    test_model.add(MaxPooling2D((3,3), strides=1))\n",
    "    if (howmany == 'fourth'):\n",
    "        test_model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "        return test_model\n",
    "    test_model.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
    "    test_model.add(MaxPooling2D((3,3), strides=1))\n",
    "    test_model.add(Flatten())\n",
    "    test_model.add(Dense(256, activation='relu'))\n",
    "    test_model.add(Dense(10, activation='softmax'))\n",
    "    test_model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "    return test_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code to help with image detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this code is very heavily commented in order for the user to understand \n",
    "#rewrote the above into a function as asked for in the hw above part A\n",
    "def reimage (rects, image, defaultSize):\n",
    "    # initialize the list of region proposals that we'll be classifying\n",
    "    # along with their associated bounding boxes\n",
    "    proposals = []\n",
    "    boxes = []\n",
    "\n",
    "# loop over the region proposal bounding box coordinates generated by\n",
    "# running selective search\n",
    "    for (x, y, w, h) in rects:\n",
    "\t# if the width or height of the region is less than 10% of the\n",
    "\t# image width or height, ignore it (i.e., filter out small\n",
    "\t# objects that are likely false-positives)\n",
    "        if w / float(W) < 0.1 or h / float(H) < 0.1:\n",
    "            continue\n",
    "\n",
    "\t# extract the region from the input image, convert it from BGR to\n",
    "\t# RGB channel ordering, and then resize it to 224x224 (the input\n",
    "\t# dimensions required by our pre-trained CNN)\n",
    "        roi = image[y:y + h, x:x + w]\n",
    "        roi = cv2.cvtColor(roi, cv2.COLOR_BGR2RGB)\n",
    "        roi = cv2.resize(roi, defaultSize)\n",
    "\n",
    "\t# further preprocess by the ROI\n",
    "        roi = img_to_array(roi)\n",
    "        roi = preprocess_input(roi)\n",
    "\n",
    "\t# update our proposals and bounding boxes lists\n",
    "        proposals.append(roi)\n",
    "        boxes.append((x, y, w, h))\n",
    "    \n",
    "# convert the proposals list into NumPy array and show its dimensions\n",
    "    proposals = np.array(proposals)\n",
    "    print(\"[INFO] proposal shape: {}\".format(proposals.shape))\n",
    "    return proposals, boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code is also heavily commented to make it easy for the user to comprehend what is going on\n",
    "#rewrote the function above in order to satisfy part A\n",
    "def winapproach (strides, image, fixedwin): #strides has to be in the form\n",
    "    #of (y,x) with x being the stride length in the x direction and y being \n",
    "    #the stride length in the y direction\n",
    "    #fixed win is the fixed size windows\n",
    "    # initialize the list of region proposals that we'll be classifying\n",
    "    # along with their associated bounding boxes\n",
    "    proposals = []\n",
    "    boxes = []\n",
    "    newx = 0\n",
    "    newy = 0\n",
    "    xlim = image.shape[1] - fixedwin[1] #to find the limit in the x direction\n",
    "    #subtract the shaped of the image by the  direction of the fixedwin\n",
    "    ylim = image.shape[0] - fixedwin[0]\n",
    "    xrange = int (xlim / strides) #then divide it by the stride in order to know\n",
    "    #how many times the fixed win fits in the image given the stride length\n",
    "    yrange = int(ylim / strides)\n",
    "# loop over the region proposal bounding box coordinates generated by\n",
    "# running selective search\n",
    "    for x in range (0, xrange):\n",
    "        newx = newx + strides\n",
    "        newy=0\n",
    "        for y in range (0, yrange):\n",
    "            \n",
    "            roi = image[newy:fixedwin[0] + newy, newx:fixedwin[1] + newx]\n",
    "#Now the roi has starting coordinates of 0,0 for the first iteration then it \n",
    "#moves by whatever the strid length is for each iteration the corresponding \n",
    "#box is the whatever the staring coordinate plus the fixed window size\n",
    "            #print(newx,newy)\n",
    "            roi = cv2.cvtColor(roi, cv2.COLOR_BGR2RGB)\n",
    "            roi = cv2.resize(roi, (224,224))\n",
    "            \n",
    "            newy = newy + strides\n",
    "            roi = img_to_array(roi)\n",
    "            roi = preprocess_input(roi)\n",
    "            proposals.append(roi)\n",
    "            boxes.append((newx, newy, fixedwin[1], fixedwin[0]))\n",
    "    proposals = np.array(proposals)\n",
    "    print(\"[INFO] proposal shape: {}\".format(proposals.shape))\n",
    "    return proposals, boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to get the time that a classification takes \n",
    "# classify each of the proposal ROIs using ResNet and then decode the\n",
    "# predictions\n",
    "#created this into a function to return predictions and time it takes for part F\n",
    "def classifiying(someproposals):\n",
    "    print(\"[INFO] classifying proposals...\")\n",
    "    startTime = cv2.getTickCount() # get the time it takes to do model.predict\n",
    "    preds = model.predict(someproposals)\n",
    "    endTime = cv2.getTickCount()\n",
    "    timePredict = (e2 - e1)/ cv2.getTickFrequency()\n",
    "    preds = imagenet_utils.decode_predictions(preds, top=1)\n",
    "    return preds, timePredict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function in order to get the labels and confidence of an image detection have to pass in predictions the boxes the label filters and confidence\n",
    "#created the above function into a code with a conf variable for part d\n",
    "def findlabels(preds, boxes, labelFilters, conf):\n",
    "# initialize a dictionary which maps class labels (keys) to any\n",
    "# bounding box associated with that label (values)\n",
    "    labels = {}\n",
    "\n",
    "# loop over the predictions\n",
    "    for (i, p) in enumerate(preds):\n",
    "\t# grab the prediction information for the current region proposal\n",
    "        (imagenetID, label, prob) = p[0]\n",
    "        print (label)\n",
    "\n",
    "\t# only if the label filters are not empty *and* the label does not\n",
    "\t# exist in the list, then ignore it\n",
    "        if labelFilters is not None and label not in labelFilters:\n",
    "            continue\n",
    "\n",
    "\t# filter out weak detections by ensuring the predicted probability\n",
    "\t# is greater than the minimum probability\n",
    "        if prob >= conf:\n",
    "\t\t# grab the bounding box associated with the prediction and\n",
    "\t\t# convert the coordinates\n",
    "            print(i)\n",
    "            if(i==540):\n",
    "                return labels, box\n",
    "            if(boxs[i]>((H,W))):\n",
    "                continue\n",
    "            (x, y, w, h) = boxs[i]\n",
    "\n",
    "            box = (x, y, x + w, y + h)\n",
    "\n",
    "\t\t# grab the list of predictions for the label and add the\n",
    "\t\t# bounding box + probability to the list\n",
    "            L = labels.get(label, [])\n",
    "            L.append((box, prob))\n",
    "            labels[label] = L\n",
    "    return labels, box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code in order to find a desiered object in an image with the predictions \n",
    "# all the user has to pass in the labels and the code does the rest and returns the prediction where the desired object\n",
    "#is in an image with a box surronding it \n",
    "def finalpred(labels):\n",
    "# loop over the labels for each of detected objects in the image\n",
    "    for label in labels.keys():\n",
    "\t# clone the original image so that we can draw on it\n",
    "        print(\"[INFO] showing results for '{}'\".format(label))\n",
    "\n",
    "\t# loop over all bounding boxes for the current label\n",
    "        for (box, prob) in labels[label]:\n",
    "\t\t# draw the bounding box on the image\n",
    "            (startX, startY, endX, endY) = box\n",
    "            cv2.rectangle(proposals_image, (startX, startY), (endX, endY),\n",
    "                (0, 255, 0), 2)\n",
    "\n",
    "\n",
    "\t# extract the bounding boxes and associated prediction\n",
    "\t# probabilities, then apply non-maxima suppression\n",
    "        boxes = np.array([p[0] for p in labels[label]])\n",
    "        proba = np.array([p[1] for p in labels[label]])\n",
    "        boxes = non_max_suppression(boxes, proba)\n",
    "\n",
    "\t# loop over all bounding boxes that were kept after applying\n",
    "\t# non-maxima suppression\n",
    "        for (startX, startY, endX, endY) in boxes:\n",
    "\t\t# draw the bounding box and label on the image\n",
    "            cv2.rectangle(annotated_image, (startX, startY), (endX, endY),\n",
    "                (0, 255, 0), 2)\n",
    "            y = startY - 10 if startY - 10 > 10 else startY + 10\n",
    "            cv2.putText(annotated_image, label, (startX, y),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 255, 0), 1)\n",
    "    return proposals_image, boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#functions for block search below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code to do a full search on an np.array \n",
    "#the user must pass in the xrange yrange which is a set of cordinates so it must be a list the image table which is a np.array\n",
    "#and they must pass in the square size that they want to use to search\n",
    "#this function returns the area where it is a its max in the array and the position of the max\n",
    "def fullsearch(xrange,yrange,w,imageTable, squaresize):\n",
    "    w = np.zeros((15,15))\n",
    "    x=0\n",
    "    z=0\n",
    "    for (i) in range (xrange[0],xrange[1]):\n",
    "        #print(i)\n",
    "        for j in range (yrange[0],yrange[1]):\n",
    "         #   print (j)\n",
    "        #print(i)\n",
    "            w[i][j] = imageTable[i][j]\n",
    "            z=z+1\n",
    "            if (z==squaresize):\n",
    "                z=0\n",
    "        x=x+1\n",
    "    maxvalue = np.amax(w)\n",
    "    index = np.where(w == np.amax(w))\n",
    "    return maxvalue, index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to complete a three s search on an np.array\n",
    "#the user must pass in the range for x and y in coordinate form the squaresize they want the test array they want to pass over the np.array\n",
    "#and the np array in question \n",
    "#this function returns the max value determined and the position of it\n",
    "def threess(xrange,yrange,imageTable,squaresize,testarray):\n",
    "    w = np.zeros((15,15))\n",
    "    x=0\n",
    "    z=0\n",
    "    for (i) in range (xrange[0],xrange[1]):\n",
    "        #print(i)\n",
    "        for j in range (yrange[0],yrange[1]):\n",
    "         #   print (j)\n",
    "        #print(i)\n",
    "            if(i>(squaresize)):\n",
    "                x = i-7\n",
    "            if(j>(squaresize)):\n",
    "                z = j-7\n",
    "            if(testarray[x][z]==0):\n",
    "                continue\n",
    "            w[i][j] = imageTable[i][j]\n",
    "            \n",
    "            #z=z+1\n",
    "            #if (z==squaresize):\n",
    "             #   z=0\n",
    "        #x=x+1\n",
    "    maxvalue = np.amax(w)\n",
    "    index = np.where(w == np.amax(w))\n",
    "    return maxvalue, index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#functions to help with creating a cnn\n",
    "#pass in two paths containing your test and train images and the function will rescale them and use keras to \n",
    "#create and image generator of them and return its data\n",
    "def upload_image(train_path, test_path):\n",
    "    #function to upload image from a path \n",
    "    train_d = ImageDataGenerator(rescale = 1. /255, preprocessing_function=preprocess_input)\n",
    "    test_d = ImageDataGenerator(rescale = 1. /255, preprocessing_function=preprocess_input)\n",
    "    #use of imgdatagenerator in order to rescale all the test and train images\n",
    "    train_g = train_d.flow_from_directory(train_path, target_size=(177, 254), batch_size=32)\n",
    "    print(train_g.class_indices)\n",
    "    #use flow from directory to store them and indicies and have them ready to be processed\n",
    "    test_g = test_d.flow_from_directory(test_path, target_size=(177, 254), batch_size=32)\n",
    "    #the target size is important to have but shouldn't matter too much because all the images are\n",
    "    #scaled to the proper size earlier\n",
    "    print(test_g.class_indices)\n",
    "    return (train_d, test_d, train_g, test_g)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code if you ever want to display a random image from an image path all you have to pass is the the pass and train generator from the function above\n",
    "#then it shows a random image\n",
    "def random_image(train_path, train_generator):\n",
    "    #use this function to show a random image contained inside the test generator\n",
    "    rand_img = np.random.choice(train_generator.filenames)\n",
    "    #using numpy to make a random selection inside the train_generator filenames\n",
    "    img = Image.open(train_path + rand_img)\n",
    "    #use this to open the image from the path from train generator and random file\n",
    "    print(train_path+random_img)\n",
    "    print(img.size)\n",
    "    plt.imshow(img)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to predict the class of an image \n",
    "#this can be used for more than just card types all depends on the labels the user used and it can be adjusted accordingly\n",
    "#it also returns the prediction of the class type\n",
    "def get_class(path): #use this to predict the class of a random image\n",
    "    the_img = Image.open(path).convert('RGB')\n",
    "    imgn = the_img.resize((254,177))\n",
    "    plt.imshow(the_img)\n",
    "    plt.axis('off')\n",
    "    x = np.asarray(imgn, np.float32)[None]\n",
    "    x = preprocess_input(x)\n",
    "    y = mod.predict(x)\n",
    "    \n",
    "    preds = label_dict[np.argmax(y)]\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code to help with sorting dictionaries and lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pass in one dictionary and two lists and the code will return to you the name which is from the dictionary the values and index\n",
    "#returns it in list form\n",
    "def results_in_tuple(Results, classinfo, resultobjects): # solution for part 1\n",
    "    newlist = []\n",
    "    numbersSorted = {k:v for (k,v) in enumerate(Results)} #create a sorted list here with the scores by with the index values on them in order to not lose the position of the value when sorting\n",
    "    newsort = sorted(numbersSorted.values(),reverse=False)\n",
    "    for x,y in enumerate(newsort): #go through the sorted list from above\n",
    "        new_dict = {x: (k) for (v,k) in (classinfo[resultobjects[x]].items())} #store the names of each object in a dict\n",
    "        newlist.append((y)) #store the position first\n",
    "        newlist.append((new_dict[x])) #the name second\n",
    "        newlist.append((x))#the index third which is position of it in the objects and scores list\n",
    "    return newlist # return the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#very useful code to help with creating a dictionary when the user has multiple values for something that would have the same key\n",
    "#pass in the same things as above\n",
    "#the output the key value and index in dictionary form \n",
    "def results_dictionary(Results, classinfo, resultobjects): #now for task2\n",
    "    final_dict = defaultdict(list)#use default dict in order to create a dict with duplicate keys\n",
    "    numbersSorted = {k:v for (k,v) in enumerate(Results)}\n",
    "    newsort = sorted(numbersSorted.values(),reverse=False)#same process as above for the sort\n",
    "    for h,i in enumerate(newsort):\n",
    "        new_dict = {h: (k) for (v,k) in (classinfo[resultobjects[h]].items())} #h is index i is score       \n",
    "        temp = (i,h)#create a temp of the values in order to use append\n",
    "        final_dict[new_dict[h]].append(temp)#append the score and index in the dictionary to support multiple keys\n",
    "    return (final_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
