{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse \n",
    "import glob\n",
    "import cv2 \n",
    "import os\n",
    "\n",
    "from collections import defaultdict\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image_files(image_path, conversion=cv2.COLOR_BGR2RGB):\n",
    "    image_files = glob.glob(os.path.join(image_path, '*')) #function in order to convert the images pass through the image path and conversion\n",
    "    image_list = [(os.path.basename(f),cv2.imread(f,conversion)) for f in image_files]\n",
    "    image_dict = {file:image for (file,image) in image_list}\n",
    "    return image_dict\n",
    "mylist = (0,1,2,3,4,5,6)\n",
    "number_of_bins = 8\n",
    "def bin_number(incriments):\n",
    "    number_bins = number_of_bins * incriments\n",
    "    return number_bins\n",
    "    \n",
    "\n",
    "\n",
    "def generate_histogram(image_dict, number_bins=8):\n",
    "    histogram_dict = dict()\n",
    "    for filename in image_dict: # function to take the images and create histograms for each one \n",
    "        image = image_dict[filename]\n",
    "        hist0 = cv2.calcHist([image], [0], None, [number_bins], [0,256])\n",
    "        hist1 = cv2.calcHist([image], [1], None, [number_bins], [0,256])\n",
    "        hist2 = cv2.calcHist([image], [2], None, [number_bins], [0,256])\n",
    "        overall_hist = np.concatenate([hist0,hist1,hist2]).ravel()\n",
    "        hist = overall_hist / overall_hist.sum()\n",
    "        histogram_dict[filename] = hist\n",
    "    return histogram_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image_directory = '/home/CV/HistogramDataset/'\n",
    "targets_directory = 'targets'\n",
    "mystery_directory = 'mystery' # directories for all the images \n",
    "class_directory = 'class'\n",
    "class_list = ['bulbasaur','charmander','pikachu','squirtle']\n",
    "\n",
    "\n",
    "image_target_dict = read_image_files(image_directory + targets_directory) #call the image read\n",
    "hist_target_dict = generate_histogram(image_target_dict) #create the histograms for the targets\n",
    "for i in mylist:\n",
    "    number_of_bins = bin_number(i)# use this to find the best bin number for the histograms\n",
    "    \n",
    "image_class_dict = dict()\n",
    "hist_class_dict = dict()\n",
    "for c in class_list:\n",
    "    image_class_dict[c] = read_image_files(os.path.join(image_directory,'classes',c)) #now do the same for the class images\n",
    "    hist_class_dict[c] = generate_histogram(image_class_dict[c])\n",
    "    \n",
    "image_mystery_dict = read_image_files(os.path.join(image_directory,'mystery')) #lastly same thing for the mystery images\n",
    "hist_mystery_dict = generate_histogram(image_mystery_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENCV_METHODS = (\n",
    "        (\"Correlation\", cv2.HISTCMP_CORREL, True),\n",
    "        (\"Chi-Squared\", cv2.HISTCMP_CHISQR, False),\n",
    "        (\"Intersection\", cv2.HISTCMP_INTERSECT, True,), # call the histogram matching methods and whether it is in reverse or not\n",
    "        (\"Hellinger\", cv2.HISTCMP_BHATTACHARYYA,False ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_histogram(image_name, target_hist_base, class_histogram_dict):\n",
    "    results_dict = dict()\n",
    "    for (methodName, method, reverse) in OPENCV_METHODS:\n",
    "        results = {k : cv2.compareHist(target_hist_base, hist, method) for (k,hist) in sorted(class_histogram_dict.items())} #compare the histograms pass in the targets and class\n",
    "        results = sorted([(v, k) for (k, v) in results.items()], reverse = reverse)\n",
    "        results_dict[methodName] = results\n",
    "        \n",
    "    return results_dict\n",
    "def compare_mystery(k,image_name, mystery_image_name, target_hist_base, target_hist_base_two):\n",
    "    mystery_results_dict = dict()\n",
    "    for (methodName, method, reverse) in OPENCV_METHODS:\n",
    "        mystery_results = {image_name : cv2.compareHist(target_hist_base, target_hist_base_two, method)}\n",
    "\n",
    "        mystery_results_dict[methodName] = mystery_results #create a nested dictionary containing the results of the mystery images compared with the targets\n",
    "    return mystery_results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Correlation': {'target_pikachu.png': 0.9442435604813273}, 'Chi-Squared': {'target_pikachu.png': 1.8788743753541608}, 'Intersection': {'target_pikachu.png': 0.8180390852603523}, 'Hellinger': {'target_pikachu.png': 0.3126539246082259}}\n"
     ]
    }
   ],
   "source": [
    "k=0\n",
    "mystery_class_compare_dict = dict()\n",
    "mystery_results_dict_squirtle = dict()\n",
    "mystery_results_dict_char = dict() #create dictionaries for each target pokemon to compare with the mystery pokemon\n",
    "mystery_results_dict_bulb = dict()\n",
    "mystery_results_dict_pikachu = dict()\n",
    "for (image_name, hist_base) in hist_target_dict.items():\n",
    "    target_class = image_name.split('.')[0].split('_')[1] # grab the names of each target \n",
    "    for (image_name_mystery, hist_base_two) in sorted(hist_mystery_dict.items()): # grab the names of each mystery image\n",
    "        mystery_class = image_name_mystery\n",
    "        if image_name == 'target_squirtle.png': # now for each target name call the compare mystery function and compare the target to each mystery and return a nested dictionary\n",
    "            mystery_results_dict_squirtle[mystery_class] = compare_mystery(k, image_name, image_name_mystery, hist_base, hist_base_two)\n",
    "        elif image_name == 'target_pikachu.png':\n",
    "            mystery_results_dict_pikachu[mystery_class] = compare_mystery(k, image_name, image_name_mystery, hist_base, hist_base_two)\n",
    "        elif image_name == 'target_charmander.png':\n",
    "            mystery_results_dict_char[mystery_class] = compare_mystery(k, image_name, image_name_mystery, hist_base, hist_base_two)\n",
    "        else:\n",
    "            mystery_results_dict_bulb[mystery_class] = compare_mystery(k, image_name, image_name_mystery, hist_base, hist_base_two)\n",
    "        k=k+1\n",
    "print(mystery_results_dict_pikachu[\"mystery9.png\"])#[\"Chi-Squared\"]) #now you have the test results in a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_likely_squirtle_dict=dict() #now in reading online having a negative correlation is an easy way to eliminate if it is a good match or not \n",
    "for (image_name_mystery, hist_base_two) in sorted(hist_mystery_dict.items()):\n",
    "        mystery_class = image_name_mystery\n",
    "        for (img_name_mystery, score) in (mystery_results_dict_squirtle[mystery_class]['Correlation'].items()): # take the mystery results and see if the score comes back negative \n",
    "            if score<0:\n",
    "                not_likely_squirtle_dict[mystery_class] = score #if it does then store it in a not likely dict in order to lesson the amount of images that need to be ran \n",
    "\n",
    "not_likely_pikachu_dict=dict()\n",
    "for (image_name_mystery, hist_base_two) in sorted(hist_mystery_dict.items()): #now do it for all four pokemon\n",
    "        mystery_class = image_name_mystery\n",
    "        for (img_name_mystery, score) in (mystery_results_dict_pikachu[mystery_class]['Correlation'].items()):\n",
    "            if score<0:\n",
    "                not_likely_pikachu_dict[mystery_class] = score\n",
    "\n",
    "not_likely_char_dict=dict()\n",
    "for (image_name_mystery, hist_base_two) in sorted(hist_mystery_dict.items()):\n",
    "        mystery_class = image_name_mystery\n",
    "        for (img_name_mystery, score) in (mystery_results_dict_char[mystery_class]['Correlation'].items()):\n",
    "            if score<0:\n",
    "                not_likely_char_dict[mystery_class] = score\n",
    "\n",
    "not_likely_bulb_dict=dict()\n",
    "for (image_name_mystery, hist_base_two) in sorted(hist_mystery_dict.items()):\n",
    "        mystery_class = image_name_mystery\n",
    "        for (img_name_mystery, score) in (mystery_results_dict_bulb[mystery_class]['Correlation'].items()):\n",
    "            if score<0:\n",
    "                not_likely_bulb_dict[mystery_class] = score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.035500856377805\n",
      "mystery1.png\n",
      "0.5546843375583982\n",
      "mystery10.png\n",
      "14.482979355922655\n",
      "mystery2.png\n",
      "14.590161034958513\n",
      "mystery3.png\n",
      "3.4285130722248445\n",
      "mystery4.png\n",
      "0.5792180573918561\n",
      "mystery5.png\n",
      "32.89657179115637\n",
      "mystery6.png\n",
      "5.464785033639735\n",
      "mystery7.png\n",
      "22.954080079992586\n",
      "mystery8.png\n",
      "3.830905912460245\n",
      "mystery9.png\n"
     ]
    }
   ],
   "source": [
    "for (image_name_mystery, hist_base_two) in sorted(hist_mystery_dict.items()):\n",
    "    for (img_name, target_score) in sorted(mystery_results_dict_squirtle[image_name_mystery]['Chi-Squared'].items()):\n",
    "        print(target_score)\n",
    "        if(target_score<0):\n",
    "            print('h')\n",
    "            print(image_name_mystery)\n",
    "        print(image_name_mystery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_class_compare_dict = defaultdict(dict) # create the target and class compare dictionary compare the 10 class images to the target image\n",
    "for (image_name, hist_base) in hist_target_dict.items():\n",
    "    target_class = image_name.split('.')[0].split('_')[1]\n",
    "    for class_name in class_list:\n",
    "        target_class_compare_dict[target_class][class_name] = compare_histogram(image_name, hist_base, hist_class_dict[class_name]) # return a dictionary of each one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.8578661145484695, '4.png'), (0.84162808425238, '5.png'), (0.44570073193045195, '8.png'), (0.23110706517289242, '1.png'), (0.2247963657183375, '3.png'), (0.13955487527445715, '2.png'), (0.1368973884684922, '10.png'), (0.10035062431161372, '9.png'), (0.003744007402371596, '6.png'), (-0.016282192773904566, '7.png')]\n",
      "[(4.931336213403033, '4.png'), (5.417565339664923, '5.png'), (14.206473893927633, '8.png'), (118.99473069111978, '6.png'), (124.85376912042297, '9.png'), (127.46875617934086, '3.png'), (171.0141086702477, '1.png'), (205.53732572274455, '2.png'), (230.05023244406289, '10.png'), (263.53594529481586, '7.png')]\n",
      "[(0.7678928186151097, '4.png'), (0.7569464569105548, '5.png'), (0.4701646773610264, '8.png'), (0.3691336225019768, '9.png'), (0.36850067116029095, '1.png'), (0.3270427668094271, '3.png'), (0.31299965757534665, '10.png'), (0.30633111015777104, '2.png'), (0.1972729716799222, '6.png'), (0.1938923991547199, '7.png')]\n",
      "[(0.3420150627382142, '5.png'), (0.3531722224349389, '4.png'), (0.5395408922933272, '8.png'), (0.5866130644243498, '9.png'), (0.6022696344926354, '1.png'), (0.6458126460692807, '10.png'), (0.6507451146545344, '3.png'), (0.6645802081513009, '2.png'), (0.7107997453382164, '6.png'), (0.7537633909224937, '7.png')]\n"
     ]
    }
   ],
   "source": [
    "print (target_class_compare_dict['pikachu']['pikachu'][\"Correlation\"])\n",
    "print (target_class_compare_dict['pikachu']['pikachu'][\"Chi-Squared\"])\n",
    "print (target_class_compare_dict['pikachu']['pikachu'][\"Intersection\"]) # call the target class compare dict and pring the results\n",
    "print (target_class_compare_dict['pikachu']['pikachu'][\"Hellinger\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1.5640142784473547, '8.png'), (10.053827906141446, '9.png'), (10.76300779186892, '6.png'), (23.969043773208583, '5.png'), (51.88595028699742, '2.png'), (62.66979879006354, '3.png'), (62.742862620225985, '7.png'), (84.25463774091708, '4.png'), (89.68251770080992, '1.png'), (231.1542099032823, '10.png')]\n"
     ]
    }
   ],
   "source": [
    "#print (target_class_compare_dict['pikachu']['pikachu'][\"Correlation\"])\n",
    "#print (target_class_compare_dict['pikachu']['charmander'][\"Correlation\"])\n",
    "print (target_class_compare_dict['pikachu']['bulbasaur'][\"Chi-Squared\"])\n",
    "#print (target_class_compare_dict['pikachu']['squirtle'][\"Correlation\"]) # now compare the targets and classes of different pokemon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.2965363064305562, 0.13955487527445715, 0.8578661145484695, -0.016282192773904566, {}, {'Correlation': 0.2965363064305562})\n",
      "(0.1514228390502689, -0.13469173260029785, 0.927982643066907, -0.24768712263804848, {}, {'Correlation': 0.1514228390502689})\n",
      "(0.12540807304591636, -0.05377971071306663, 0.7935632915327747, -0.3031291439284923, {}, {'Correlation': 0.12540807304591636})\n",
      "(0.6040641630036514, 0.8762430517079068, 0.9648501528862824, 0.10541783508926617, {'Correlation': 0.6040641630036514}, {'Correlation': 0.6040641630036514})\n",
      "\n",
      "(126.60102435697502, 127.46875617934086, 263.53594529481586, 4.931336213403033, {'Chi-Squared': 126.60102435697502}, {'Correlation': 0.6040641630036514, 'Chi-Squared': 126.60102435697502})\n",
      "(9.578015977446471, 11.25632707365451, 23.144474813917498, 0.7415842370288771, {'Chi-Squared': 9.578015977446471}, {'Correlation': 0.6040641630036514, 'Chi-Squared': 9.578015977446471})\n",
      "(9.364504374756896, 7.4134596193500935, 35.005377981356226, 0.770919824265436, {}, {'Correlation': 0.6040641630036514, 'Chi-Squared': 9.364504374756896})\n",
      "(8.082067332929675, 2.452492467463056, 23.17409922179755, 0.23793097778342046, {}, {'Correlation': 0.6040641630036514, 'Chi-Squared': 8.082067332929675})\n",
      "\n",
      "(0.40701771519261454, 0.3270427668094271, 0.7678928186151097, 0.1938923991547199, {}, {'Correlation': 0.6040641630036514, 'Chi-Squared': 8.082067332929675, 'Intersection': 0.40701771519261454})\n",
      "(0.47503083879710173, 0.3663450510939583, 0.8007699877489358, 0.2775723763043061, {}, {'Correlation': 0.6040641630036514, 'Chi-Squared': 8.082067332929675, 'Intersection': 0.47503083879710173})\n",
      "(0.508963367063916, 0.4957114947028458, 0.7038466444973892, 0.27926091593690217, {}, {'Correlation': 0.6040641630036514, 'Chi-Squared': 8.082067332929675, 'Intersection': 0.508963367063916})\n",
      "(0.5942276369540196, 0.7076556793908821, 0.8179041574767325, 0.2921979373204522, {'Intersection': 0.5942276369540196}, {'Correlation': 0.6040641630036514, 'Chi-Squared': 8.082067332929675, 'Intersection': 0.5942276369540196})\n",
      "\n",
      "(0.5849311981519292, 0.6458126460692807, 0.7537633909224937, 0.3420150627382142, {'Hellinger': 0.5849311981519292}, {'Correlation': 0.6040641630036514, 'Chi-Squared': 8.082067332929675, 'Intersection': 0.5942276369540196, 'Hellinger': 0.5849311981519292})\n",
      "(0.511312558338952, 0.5798926910849629, 0.691736908936298, 0.23414633854244654, {'Hellinger': 0.511312558338952}, {'Correlation': 0.6040641630036514, 'Chi-Squared': 8.082067332929675, 'Intersection': 0.5942276369540196, 'Hellinger': 0.511312558338952})\n",
      "(0.47130682561001114, 0.4800392000657665, 0.6707914628287334, 0.32561398352675874, {'Hellinger': 0.47130682561001114}, {'Correlation': 0.6040641630036514, 'Chi-Squared': 8.082067332929675, 'Intersection': 0.5942276369540196, 'Hellinger': 0.47130682561001114})\n",
      "(0.4217864947876193, 0.37424592298416987, 0.6252896170669568, 0.24010376650201443, {}, {'Correlation': 0.6040641630036514, 'Chi-Squared': 8.082067332929675, 'Intersection': 0.5942276369540196, 'Hellinger': 0.4217864947876193})\n",
      "\n",
      "{'Hellinger': 0.47130682561001114}\n",
      "{'Chi-Squared': 126.60102435697502, 'Hellinger': 0.5849311981519292}\n",
      "{'Chi-Squared': 9.578015977446471, 'Hellinger': 0.511312558338952}\n",
      "0.6040641630036514\n"
     ]
    }
   ],
   "source": [
    "pTest = '0'\n",
    "bulbTest = dict()\n",
    "pikachuTest = dict()\n",
    "charTest = dict()\n",
    "squirtleTest = dict()\n",
    "avg_score = 0\n",
    "avg_score_dict = dict()\n",
    "max_avg_score_dict = dict()\n",
    "max_avg_score_dict_pikachu = dict()\n",
    "max_avg_score_dict_squirtle = dict()\n",
    "max_avg_score_dict_char = dict()\n",
    "max_avg_score_dict_bulb = dict()\n",
    "max_array = []\n",
    "#preferredTest = dict()\n",
    "p_test_pikachu = dict()\n",
    "p_test_squirtle = dict()\n",
    "p_test_bulb = dict()\n",
    "p_test_char = dict()\n",
    "def calculate_score_range(histogram_scores_tuple): #calculate the range of scores \n",
    "    preferredTest = dict()\n",
    "    scores = [score for (score,filename) in histogram_scores_tuple] #grab the file scores from the target class compare results\n",
    "    median_score = scores[int(len(scores)/2)]\n",
    "    max_score = max(scores)\n",
    "    min_score = min(scores)\n",
    "    avg_score = sum(scores)/len(scores) #calculate the median avg max and min\n",
    "    if(avg_score < median_score): \n",
    "        pTest= [methodName]\n",
    "        preferredTest[methodName]= (avg_score)\n",
    "\n",
    "    avg_score_dict[methodName] = avg_score\n",
    "\n",
    "    return (avg_score, median_score, max_score, min_score, preferredTest, avg_score_dict)\n",
    "def calc_avg_score(histogram_scores_tuple):\n",
    "    theScores = [score for (score,filename) in histogram_scores_tuple] \n",
    "    avgScore = sum(theScores)/len(theScores)\n",
    "    medianScore = theScores[int(len(theScores)/2)] #take the average score and the median score if the avgscore is less than the median that means we get a lot of strong hits\n",
    "    if(avgScore < medianScore): \n",
    "        return (avgScore) #if it is less than then return the avg score else return 0\n",
    "    else:\n",
    "        return 0 \n",
    "    \n",
    "calc_score_dict = dict()\n",
    "calc_correlation_dict = dict()\n",
    "i = [0,1,2,3]\n",
    "j = [0,1,2,3]\n",
    "x = 3\n",
    "pikachu_name = 'pikachu'\n",
    "squirtle_name = 'squirtle'\n",
    "bulb_name = 'bulbasaur'\n",
    "char_name = 'charmander'\n",
    "\n",
    "for (methodName, method, reverse) in OPENCV_METHODS:\n",
    "    print (calculate_score_range(target_class_compare_dict[pikachu_name][pikachu_name][methodName])) #print the average max min and median\n",
    "    max_avg_score_dict_pikachu[pikachu_name] = avg_score_dict # store the max average score for each test\n",
    "    rand = calc_avg_score(target_class_compare_dict[pikachu_name][pikachu_name][methodName]) #store the average score only for the tests that have an avg less than the median\n",
    "    if (rand != 0): #if it returns something other than zero then store the score with the test name\n",
    "        pikachuTest[methodName] = rand\n",
    "    print (calculate_score_range(target_class_compare_dict[squirtle_name][squirtle_name][methodName]))\n",
    "    max_avg_score_dict_squirtle[squirtle_name] = avg_score_dict\n",
    "    rand = calc_avg_score(target_class_compare_dict[squirtle_name][squirtle_name][methodName])\n",
    "    if (rand != 0):\n",
    "        squirtleTest[methodName] = rand\n",
    "    print (calculate_score_range(target_class_compare_dict[bulb_name][bulb_name][methodName]))\n",
    "    max_avg_score_dict_bulb[methodName] = avg_score_dict\n",
    "    rando = calc_avg_score(target_class_compare_dict[bulb_name][bulb_name][methodName])\n",
    "    if (rando != 0):\n",
    "        bulbTest[methodName] = rando\n",
    "    print (calculate_score_range(target_class_compare_dict[char_name][char_name][methodName]))\n",
    "    max_avg_score_dict_char[char_name] = avg_score_dict\n",
    "    rando = calc_avg_score(target_class_compare_dict[char_name][char_name][methodName])\n",
    "    if (rando != 0):\n",
    "        charTest[methodName] = rando\n",
    "\n",
    "    print()\n",
    "\n",
    "\n",
    "#print (max_avg_score_dict_pikachu)\n",
    "#print (max_avg_score_dict_char)\n",
    "\n",
    "print(bulbTest)\n",
    "print(pikachuTest)\n",
    "print(squirtleTest)\n",
    "print(charTest['Correlation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Hellinger': 0.47130682561001114}\n"
     ]
    }
   ],
   "source": [
    "print(avg_score_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Chi-Squared': {'mystery1.png': 19.035500856377805, 'mystery2.png': 14.482979355922655, 'mystery3.png': 14.590161034958513, 'mystery6.png': 32.89657179115637, 'mystery8.png': 22.954080079992586}, 'Hellinger': {'mystery1.png': 0.7349577724675438, 'mystery2.png': 0.6240251331278139, 'mystery3.png': 0.6259042523949876, 'mystery6.png': 0.778065165643972, 'mystery8.png': 0.7039022386288077}}\n",
      "Squirtle  \n",
      "{'Hellinger': {'mystery1.png': 0.7487742013285382, 'mystery2.png': 0.6119421001712279, 'mystery3.png': 0.6246168394065275, 'mystery4.png': 0.5453211348696826, 'mystery6.png': 0.7964293967547684, 'mystery7.png': 0.5062754955097309, 'mystery8.png': 0.7281508806358205, 'mystery9.png': 0.5394314584613887}}\n",
      "bulb \n",
      "{'Correlation': {'mystery10.png': 0.9082651810061503, 'mystery4.png': 0.8775633277413312, 'mystery5.png': 0.9338797740941831, 'mystery7.png': 0.8496687041254094, 'mystery9.png': 0.9211785909977198}, 'Intersection': {'mystery10.png': 0.7614872007397935, 'mystery4.png': 0.7163735327121685, 'mystery5.png': 0.7878238250195864, 'mystery7.png': 0.6924666644772515, 'mystery9.png': 0.7374292244303433}}\n",
      "char\n",
      "{'Chi-Squared': {'mystery2.png': 185.14005362021598, 'mystery3.png': 175.88048547732402, 'mystery6.png': 371.6684666778582, 'mystery8.png': 236.0330111128354}, 'Hellinger': {'mystery1.png': 0.6877063363534573, 'mystery2.png': 0.6728895081270917, 'mystery3.png': 0.6590692856756372, 'mystery6.png': 0.7674230660724523, 'mystery8.png': 0.72872806744484}}\n"
     ]
    }
   ],
   "source": [
    "possible_squirtle_dict=dict()\n",
    "possible_char_dict = dict()\n",
    "possible_pikachu_dict = dict()\n",
    "possible_bulb_dict = dict()\n",
    "\n",
    "def greater_than_avg(the_method, myst_results_dict): # run the preferred test from above for each pokemon \n",
    "    greater_than_avg=dict()\n",
    "    for (image_name_mystery, hist_base_two) in sorted(hist_mystery_dict.items()):\n",
    "        for (img_name, target_score) in sorted(myst_results_dict[image_name_mystery][the_method].items()): \n",
    "            for (img_name_mystery, score) in (myst_results_dict[image_name_mystery][the_method].items()):\n",
    "                if(score>average_score):\n",
    "                    greater_than_avg[image_name_mystery] = score # return the mystery images that score above average for the preferred test\n",
    "    return greater_than_avg\n",
    "\n",
    "for (method_name, average_score) in (squirtleTest.items()):\n",
    "    possible_squirtle_dict[method_name] = greater_than_avg(method_name, mystery_results_dict_squirtle) # run the greater than avg for all four pokemon and store the score \n",
    "print(possible_squirtle_dict)  #and image name as potentially a hit for that pokemon and do it for all four\n",
    "print('Squirtle  ')\n",
    "\n",
    "for (method_name, average_score) in (bulbTest.items()):\n",
    "    possible_bulb_dict[method_name] = greater_than_avg(method_name, mystery_results_dict_bulb)\n",
    "print(possible_bulb_dict)  \n",
    "print('bulb ')\n",
    "for (method_name, average_score) in (charTest.items()):\n",
    "    possible_char_dict[method_name] = greater_than_avg(method_name, mystery_results_dict_char)\n",
    "print(possible_char_dict)\n",
    "print('char')\n",
    "\n",
    "for (method_name, average_score) in (pikachuTest.items()):\n",
    "    possible_pikachu_dict[method_name] = greater_than_avg(method_name, mystery_results_dict_pikachu)\n",
    "print(possible_pikachu_dict)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chi-Squared\n",
      "{'mystery1.png': 19.035500856377805, 'mystery2.png': 14.482979355922655, 'mystery3.png': 14.590161034958513, 'mystery6.png': 32.89657179115637, 'mystery8.png': 22.954080079992586}\n",
      "mystery1.png\n",
      "mystery2.png\n",
      "mystery3.png\n",
      "mystery6.png\n",
      "mystery8.png\n",
      "Hellinger\n",
      "{'mystery1.png': 0.7349577724675438, 'mystery2.png': 0.6240251331278139, 'mystery3.png': 0.6259042523949876, 'mystery6.png': 0.778065165643972, 'mystery8.png': 0.7039022386288077}\n",
      "mystery1.png\n",
      "mystery2.png\n",
      "mystery3.png\n",
      "mystery6.png\n",
      "mystery8.png\n",
      "{'mystery1.png': 0.7349577724675438, 'mystery2.png': 0.6240251331278139, 'mystery3.png': 0.6259042523949876, 'mystery6.png': 0.778065165643972, 'mystery8.png': 0.7039022386288077}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pSquirtleName = dict()\n",
    "for (imag, sre) in (possible_squirtle_dict.items()):\n",
    "    print(imag)\n",
    "    print(sre)\n",
    "    for(iname, so) in (sre.items()):\n",
    "        print(iname)\n",
    "        pSquirtleName[iname] = so\n",
    "print(pSquirtleName) #just trying some things out for squirtle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "{'mystery10.png': 0.9155755250086286, 'mystery5.png': 0.8310934660525131}\n",
      "hehe\n",
      "hehe\n",
      "{'mystery1.png': 0.6877063363534573}\n",
      "{'mystery1.png': 0.6877063363534573}\n",
      "{'mystery10.png': 0.9155755250086286, 'mystery5.png': 0.8310934660525131}\n"
     ]
    }
   ],
   "source": [
    "#match_dict = 0\n",
    "def comparision_funct(target_name,not_likely_dict, mystery_results_dict, preferredTest,image_name, test, number):\n",
    "    thresh = -.5\n",
    "    avg = preferredTest[test] #last comaprision fucntion hopefully take the average from the test passed in\n",
    "\n",
    "    if(image_name) in (not_likely_dict): #if the image is in the not likely dictionary then skip it in order to streamline the process\n",
    "        return 0\n",
    "\n",
    "    for (img_name, target_score) in sorted(mystery_results_dict[image_name][test].items()): #Now take the image name and target score from the mystery resluts dict\n",
    "            #if(image_name_mystery in match_dict):\n",
    "             #   continue\n",
    "                #if(target_score > avg):\n",
    "            pError = ((avg - target_score)/(target_score)) #using the good ole reliable percent error because if its negative it means its much higher than the avg so match\n",
    "            if(pError < number): #if the p error is less than target number store the score and return the value to be put into a dict with the mystery image\n",
    "                match_dict = target_score\n",
    "                confirmedTest = image_name_mystery\n",
    "                return(match_dict)#, confirmedTest) #so far is works better just returning the number but keeping it commeneted just in case\n",
    "                    \n",
    "            else:\n",
    "                return 0 #if it isn't less than then return 0 to keep that area in the dictionary empty\n",
    "\n",
    "def calc_avg_score_total(histogram_scores_tuple):\n",
    "    theScores = [score for (score,filename) in histogram_scores_tuple]\n",
    "    avgScore = sum(theScores)/len(theScores) #created a new function to return the average total of all the tests not just one\n",
    "    return avgScore\n",
    "test_number = -.84 #using .84 because online I gathered that .9 is a strong reliable number so taking that minus the average divided by should give a strong number thus .84\n",
    "bulb_match = dict()\n",
    "for (image_name_mystery, hist_base_two) in sorted(mystery_results_dict_bulb.items()): #now I'm starting with bulbasuar because it only has one test making it the easiest and \n",
    "    for (test) in bulbTest: #fastest to run to knock out some hits \n",
    "        compare = comparision_funct(bulb_name, not_likely_bulb_dict, mystery_results_dict_bulb, bulbTest, image_name_mystery, test, test_number) #call the compare function from above\n",
    "        if compare != 0: #if it returns to us a value that isn't 0 meaning it is a match then store it in a dictionary\n",
    "        #print(compare)\n",
    "            bulb_match[image_name_mystery] = compare\n",
    "print(bulb_match)      #print the match dictionary to see the matches    \n",
    "if len(bulb_match) == 0: #if the length of the dictionary is 0 it means there are no matches so try again \n",
    "    for (methodName, method, reverse) in OPENCV_METHODS: #now this time since one test isn't conclusive we need to run all the test to see if we get any results\n",
    "        max_avg_score_dict_bulb[methodName] = calc_avg_score_total(target_class_compare_dict[bulb_name][bulb_name][methodName]) #call this in order to get the average score of all the tests\n",
    "        for (image_name_mystery, hist_base_two) in sorted(mystery_results_dict_bulb.items()):\n",
    "            compare1 = comparision_funct(bulb_name, not_likely_bulb_dict, mystery_results_dict_bulb, max_avg_score_dict_bulb, image_name_mystery, methodName, test_number)\n",
    "#recall the comparison function and run it for all the tests and try again\n",
    "            if compare1 != 0:\n",
    "                bulb_match[image_name_mystery] = compare1 #if the function returns something other than zeros it is a match\n",
    "print(bulb_match) #hopefully it is a match\n",
    "pikachu_match = dict()\n",
    "pikachu_test_number=0 #now try the same method for pikachu we want matches\n",
    "for (image_name_mystery, hist_base_two) in sorted(mystery_results_dict_pikachu.items()):\n",
    "    if(image_name_mystery) in (bulb_match): #skip the images that are matches for bulbasaur to limit the number of images being passed\n",
    "        print('hehe')\n",
    "        continue\n",
    "    for (test) in pikachuTest:\n",
    "        compare = comparision_funct(pikachu_name, not_likely_pikachu_dict, mystery_results_dict_pikachu, pikachuTest, image_name_mystery, test, pikachu_test_number)\n",
    "        if compare != 0:\n",
    "            pikachu_match[image_name_mystery] = compare   \n",
    "print(pikachu_match)\n",
    "for (methodName, method, reverse) in OPENCV_METHODS: #same thing if it is empty run again\n",
    "        max_avg_score_dict_pikachu[methodName] = calc_avg_score_total(target_class_compare_dict[pikachu_name][pikachu_name][methodName])\n",
    "        for (image_name_mystery, hist_base_two) in sorted(mystery_results_dict_pikachu.items()):\n",
    "            compare1 = comparision_funct(pikachu_name, not_likely_pikachu_dict, mystery_results_dict_pikachu, max_avg_score_dict_pikachu, image_name_mystery, methodName, test_number)\n",
    "            if compare1 != 0:\n",
    "                pikachu_match[image_name_mystery] = compare1    \n",
    "print(pikachu_match)\n",
    "print(bulb_match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mystery4.png': 0.7163735327121685, 'mystery7.png': 0.6924666644772515, 'mystery9.png': 0.7374292244303433}\n",
      "{'Correlation': {'mystery4.png': 0.7163735327121685, 'mystery7.png': 0.6924666644772515, 'mystery9.png': 0.7374292244303433}, 'Intersection': {'mystery4.png': 0.7163735327121685, 'mystery7.png': 0.6924666644772515, 'mystery9.png': 0.7374292244303433}}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_number = 0\n",
    "char_match = dict() #now run this all over again for charmander and skip the images in bulb match and pikachu match\n",
    "char_char = dict()\n",
    "for (image_name_mystery, hist_base_two) in sorted(mystery_results_dict_char.items()):\n",
    "    \n",
    "    if(image_name_mystery) in (bulb_match):\n",
    "        continue\n",
    "    if(image_name_mystery) in (pikachu_match):\n",
    "        continue\n",
    "    for (test) in charTest:\n",
    "        compare = comparision_funct(char_name, not_likely_char_dict, mystery_results_dict_char, charTest, image_name_mystery, test, test_number)\n",
    "        if compare != 0:\n",
    "            char_match[image_name_mystery] = compare\n",
    "            char_char[test] = char_match #messed around with creating a nested for loop just to see what would happen for the char match\n",
    "print(char_match)\n",
    "print(char_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "test_number = 0\n",
    "squirtle_match = dict() #now run this all over again one last time for squirtle and skip the images in bulb match and pikachu match and char match\n",
    "squirtle_squirtle = dict()\n",
    "for (image_name_mystery, hist_base_two) in sorted(mystery_results_dict_squirtle.items()):\n",
    "    \n",
    "    if(image_name_mystery) in (bulb_match):\n",
    "        continue\n",
    "    if(image_name_mystery) in (pikachu_match):\n",
    "        continue\n",
    "    if(image_name_mystery) in (char_match):\n",
    "        continue\n",
    "    for (test) in squirtleTest:\n",
    "        compare = comparision_funct(squirtle_name, not_likely_squirtle_dict, mystery_results_dict_squirtle, squirtleTest, image_name_mystery, test, test_number)\n",
    "        if compare != 0:\n",
    "            squirtle_match[image_name_mystery] = compare\n",
    "            squirtle_squirtle[test] = char_match\n",
    "print(squirtle_match)\n",
    "print(squirtle_squirtle) #i acknowledge the fact that this is empty mainly because all the others are matches or not likely but for the sake of consistency and maybe this is ran with other images I wrote it for squirtle as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mystery2.png': 'mystery2.png', 'mystery3.png': 'mystery3.png', 'mystery6.png': 'mystery6.png', 'mystery8.png': 'mystery8.png'}\n",
      "The Bulbasaur matches are: \n",
      "{'mystery10.png': 0.9155755250086286, 'mystery5.png': 0.8310934660525131}\n",
      "The pikachu matches are: \n",
      "{'mystery1.png': 0.6877063363534573}\n",
      "The charmander matches are: \n",
      "{'mystery4.png': 0.7163735327121685, 'mystery7.png': 0.6924666644772515, 'mystery9.png': 0.7374292244303433}\n",
      "The Squirtle matches are: \n",
      "{}\n",
      "The no matches are :\n",
      "{'mystery2.png': 'mystery2.png', 'mystery3.png': 'mystery3.png', 'mystery6.png': 'mystery6.png', 'mystery8.png': 'mystery8.png'}\n"
     ]
    }
   ],
   "source": [
    "no_match_dict = dict() #now go through the match dictionaries and find the images that didn't match with anything and store them in a no match dict\n",
    "for (image_name_mystery, hist_base_two) in sorted(mystery_results_dict_squirtle.items()):\n",
    "    if(image_name_mystery) in (bulb_match):\n",
    "        continue\n",
    "    if(image_name_mystery) in (pikachu_match):\n",
    "        continue\n",
    "    if(image_name_mystery) in (char_match):\n",
    "        continue\n",
    "    if(image_name_mystery) in (squirtle_match):\n",
    "        continue\n",
    "    no_match_dict[image_name_mystery] = image_name_mystery\n",
    "print(no_match_dict)\n",
    "\n",
    "print('The Bulbasaur matches are: ')\n",
    "print(bulb_match)\n",
    "print('The pikachu matches are: ')\n",
    "print(pikachu_match)\n",
    "print('The charmander matches are: ')\n",
    "print(char_match)\n",
    "print('The Squirtle matches are: ')\n",
    "print(squirtle_match)\n",
    "print('The no matches are :')\n",
    "print(no_match_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
